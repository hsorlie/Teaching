---
title: ""
output: html_document
---
What is the Central Limit Theorem, and why is it important in statistics? We'll get to that, but first let's roll some dice!

**First, try throwing one die one time** (both sliders at 1), and repeat a few times (click the button) just to get a feeling for the plot. With one die, the range of possible total values for a throw is 1-6, as can be seen on the X-axis. So if you throw *one* die, the plot will show *one* blue bar with a height of 1 (the number of times you got that result) for the value shown on that die. **Now, change the bottom slider to a slightly larger number,** which simulates *repeating* that throw of one die at a time. The range of the X-axis stays the same since you throw one die at a time, but the bars now represent how many times you got a 1, how many times you got a 2, etc.

**Experiment with number of throws, keeping the number of dice per throw at 1.** If the die is fair (it is. I promise.) there is a 1/6 chance of getting a 1, a 1/6 chance of getting a 2.. etc, and a 1/6 chance of getting a 6. This seems obvious, but we are interested in the *total* value obtained per throw, and the notable point is this: *Since there is only one die, there is only one possible way in which to get a total value per throw of 1*; namely, getting that 1 on your only die. With one die in your hand there is also only one possible way to get a total value of 2 for your throw, only one way to get a total value of 3, and so on. Since each possible total outcome is equally likely, the outcomes will tend to happen about as often. So as the number of throws start to get large, the bars will look increasingly equal in height.

**With two dice in your hand per throw, this changes.** First: The range of possible total values per throw is no longer 1-6, since there are two dice, but rather 2-12. This is now reflected on the X-axis. But are all possible total outcomes equally likely, as they were with one die? There is only one possible way of obtaining a total value of 2: You will need to get a 1 on both your dice. Equally, the only way to get a total value of 12 is getting 6 on both your dice.

However, there are two different ways in which you can get a total value of 3: You can either get a 1 and a 2, or you can get a 2 and a 1. These are not identical ways, since the outcome for each individual die is different. There are also two different ways of getting an 11: A 5 and a 6, or a 6 and a 5. Similarly, there are even more different ways to get a total value of 4. The following three combinations will get you there: 1-3, 2-2 and 3-1. Getting a total value of 5 can happen in four different ways: 1-4, 2-3, 3-2, 4-1. And so on. 7 is the total value which can come about in most different ways (there are six possibilities).

But back to the total values 2 and 3, which had one (1-1) and two different ways (1-2 and 2-1), respectively, of coming about. Since each of the six values on *one* die is equally likely to happen, each individual combination of values (there are 6 Ã— 6 = 36 combinations) is equally likely. 1-1, 3-6, 6-2, 3-4 etc. are all equally likely to happen, the probability being 1/36. Thus, we can expect the outcome 1-2 to happen about as often (1 in 36 times) as 1-1. However, we can also expect 2-1 (which is different from 1-2) to happen equally often. Since 1-2 and 2-1 results in the same *total* value, we can expect the total value 3 to occur about twice as often as the total value 2, which can come about in half as many different ways. The total value 3 should happen on average 2 times out of 36, or 1 time in 18. Try it, with two dice per throw, and a large number of throws.

The main takeaway so far is this: **Outcomes that can come about in more different ways are generally more likely than outcomes that can come about in fewer different ways.**

This far, our distribution of obtained values looks like a pyramid, not the famous bell-shaped curve of the normal distribution. **With three dice per hand**, the pyramid shape is gone and the distribution is starting to take on that bell shape.

The blue bars show actual throwing of dice (or the randomization equivalent done in programming language) and is simulated anew each time. When you set the slider to 10 dice and 20.000 throws, the actual repeated throwing of 10 dice 20.000 times is actually simulated, each time. Therefore, the plot will look a bit different each time, but for large numbers of throws the height of the bar visualises the probability of getting that total value compared to the other total values. And therefore, based on the reasoning above, it represents the number of different ways in which it is possible to obtain this total value. The black line is the theoretical normal distribution for the corresponding mean value and standard deviation, but not dependent on the actual throwing of the dice.

And now, enter the Central Limit Theorem. In plain terms, **the Central Limit Theorem states that outcomes that are dependent on several different independent factors will tend towards a normal distribution when the number of repetitions gets very large.** For a mathematically more correct walkthrough, check https://en.wikipedia.org/wiki/Central_limit_theorem.

However, what does this mean in everyday life? Come to think about it, quite a few outcomes are dependent on several more or less independent factors. What determines human height? Genes, or nutrition and upbringing? How about a little of both? And what determines how fast you run a 3000m run? Your physical shape, your current motivation, the weather, temperature and surface conditions, or the state of your running shoes? They likely all have a say in the matter. Come to think about it, it is quite difficult to come up with an example of an outcome that does not depend on at least a couple of different things.

Because of this, we can expect a surprisingly large amount of measurable outcomes to be at least normal-ish distributed. And the individual factors on which the outcomes depend does not have to be normally distributed themselves. That's the beauty of it! The result of tossing *one* die many times is not normally distributed, but uniformly with equal probabilities. And still, the total outcome when you put a few of the dice together becomes normally distributed. Likewise, the state of running shoes, weather, physical shape or motivation does not have to be normally distributed. But still, if you clock in the results of some hundred people running the same distance, the results would highly probably be normally distributed, because of the Central Limit Theorem.

**So what the CLT does is that it lets us confidently *expect* normal distributions to appear almost everywhere around us.** And since normal distributions are easily defined by just a few numbers (the mean and the standard deviation) and have known properties, this is very handy when doing statistics. And many statistical tests and procedures requires that the data be normally distributed. Luckily, and thanks to the CLT, they often are.

So, a note of caution: A perfectly normal distribution is never observed in the wild. At best, the actual observed distributions "tend towards" normality when the number of observations "tend towards" infinity. They don't have to be perfectly normal to be useful, though. It just means that as they are increasingly similar to a normal distribution, the easily defined theoretical normal distribution becomes an increasingly handy model for that data, and statistical tests which require normality becomes increasingly relevant. Whether our distribution is close enough normality for us to call it normal can be formally tested, but the criterion in the test is agreed upon by convention, not bestowed upon us by the universe, so the test does not exempt you from reasoning about your data and its deviance from normality.